from transformers import pipeline

# Motor de NLP: puede usar modelo en espaÃ±ol de HuggingFace
chatbot_nlp = pipeline("text-generation", model="mrm8488/GPT2-spanish", tokenizer="mrm8488/GPT2-spanish")

# Base de datos simple de preguntas frecuentes
faq = {
    "Â¿CuÃ¡l es tu nombre?": "Soy un chatbot creado para responder tus preguntas.",
    "Â¿QuÃ© puedes hacer?": "Puedo ayudarte a resolver dudas frecuentes.",
    "Â¿CÃ³mo funciona este sistema?": "Este sistema responde usando procesamiento de lenguaje natural.",
    "Â¿CuÃ¡l es tu horario de atenciÃ³n?": "Estoy disponible las 24 horas.",
    "Â¿CÃ³mo contacto a soporte?": "Puedes enviar un correo a soporte@ejemplo.com.",
    "Â¿Ofrecen garantÃ­a?": "SÃ­, ofrecemos garantÃ­a de 1 aÃ±o en todos los productos.",
    "Â¿DÃ³nde estÃ¡n ubicados?": "Nuestra oficina principal estÃ¡ en Ciudad de MÃ©xico.",
    "Â¿Tienen servicio a domicilio?": "SÃ­, ofrecemos envÃ­os a todo el paÃ­s.",
    "Â¿CÃ³mo rastreo mi pedido?": "Puedes rastrear tu pedido desde nuestra web ingresando tu nÃºmero de orden.",
    "Â¿Aceptan pagos con tarjeta?": "SÃ­, aceptamos todas las tarjetas de crÃ©dito y dÃ©bito."
}

def responder_faq(pregunta):
    for clave in faq:
        if clave.lower() in pregunta.lower():
            return faq[clave]
    return None

def chatbot():
    print("ğŸ¤– Chatbot activo. Escribe 'salir' para terminar.\n")
    
    while True:
        usuario = input("ğŸ‘¤ Ingresa tu nombre de usuario: ")
        while True:
            mensaje = input(f"{usuario}: ")
            
            if mensaje.lower() == "salir":
                print("Chatbot: Â¡Hasta luego!\n")
                break

            respuesta_faq = responder_faq(mensaje)
            if respuesta_faq:
                print(f"Chatbot: {respuesta_faq}")
            else:
                # Usa el modelo NLP si no encuentra respuesta en las FAQ
                respuesta = chatbot_nlp(mensaje, max_length=50, num_return_sequences=1)[0]['generated_text']
                print("Chatbot (NLP):", respuesta)